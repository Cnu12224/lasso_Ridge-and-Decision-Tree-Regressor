#  Lasso, Ridge & Decision Tree Regression

This project explores three regression approaches—**Lasso**, **Ridge**, and **Decision Tree Regression**—applied to real-world predictive modeling tasks.

##  Models Included

- **Lasso Regression:** Applies L1 regularization to enhance feature selection and model interpretability by zeroing out less important coefficients. :contentReference[oaicite:0]{index=0}  
- **Ridge Regression:** Uses L2 regularization to shrink coefficients while retaining all features, addressing multicollinearity and reducing overfitting. :contentReference[oaicite:1]{index=1}  
- **Decision Tree Regression:** Captures non-linear patterns by partitioning the data into regions using tree-based models. :contentReference[oaicite:2]{index=2}  

##  Why These Models?

- Regularization with Lasso and Ridge helps prevent overfitting and improves generalization.  
- Lasso enables automatic feature selection, while Ridge stabilizes coefficient estimates in correlated datasets. :contentReference[oaicite:3]{index=3}  
- Decision trees introduce flexibility by modeling non-linear relationships and handling complex interactions.

##  Technologies Used

- Python  
- scikit-learn  
- pandas, NumPy  
- Matplotlib / Seaborn  
- Jupyter Notebook

##  How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/Cnu12224/lasso_Ridge-and-Decision-Tree-Regressor.git
   cd lasso_Ridge-and-Decision-Tree-Regressor
